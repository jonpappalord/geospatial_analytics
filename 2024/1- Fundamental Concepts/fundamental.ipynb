{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Luca Pappalardo, Giovanni Mauro\n",
    "\n",
    "Geospatial Analytics, Master degree in Data Science and Business Informatics, University of Pisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Analytics - Lesson 2: Fundamental Concepts\n",
    "\n",
    "In this lesson, we will learn how to handle spatial data in Python using Shapely, Geopandas, and scikit-mobility.\n",
    "\n",
    "1. [Shapely](#shapely)\n",
    "2. [Geopandas](#geopandas)\n",
    "4. [scikit-mobility](#scikitmobility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='shapely'></a>\n",
    "# Shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [**Shapely**](https://shapely.readthedocs.io/en/stable/manual.html), the most fundamental geometric objects are `Point`, `Line` and `Polygon`, the basic ingredients when working with spatial data in vector data format. \n",
    "\n",
    "Basic knowledge of using Shapely is fundamental for understanding how geometries are stored and handled in `GeoPandas` and `scikit-mobility`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric objects consist of coordinate tuples where:\n",
    "\n",
    "- `Point` represents a single point in space. Points can be either two-dimensional $(x, y)$ or three dimensional $(x, y, z)$\n",
    "\n",
    "- `LineString` (i.e., a line) represents a sequence of points joined together to form a line. Hence, a line consist of a list of at least two coordinate tuples\n",
    "\n",
    "- `Polygon` represents a filled area that consists of a list of at least three coordinate tuples that forms the outerior ring and a (possible) list of hole polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to have a collection of geometric objects (e.g., `Polygon`s with multiple parts):\n",
    "\n",
    "- `MultiPoint` object: represents a collection of `Point`s and consists of a list of coordinate-tuples\n",
    "\n",
    "- `MultiLineString` object: represents a collection of `LineString`s and consists of a list of line-like sequences\n",
    "\n",
    "- `MultiPolygon` object: represents a collection of `Polygon`s that consists of a list of polygon-like sequences that construct from exterior ring and (possible) hole list tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary geometric objects from shapely module\n",
    "from shapely.geometry import Point, LineString, Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Point geometric object(s) with coordinates\n",
    "point1 = Point(2.2, 4.2)\n",
    "point2 = Point(7.2, -25.1)\n",
    "point3 = Point(9.26, -2.456)\n",
    "point3D = Point(9.26, -2.456, 0.57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(point1)\n",
    "point1.geom_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(point1.coords))\n",
    "print(point1.x)\n",
    "print(point1.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance between point1 and point2\n",
    "dist = point1.distance(point2)\n",
    "\n",
    "# Print out a nicely formatted info message\n",
    "print(f\"Distance between the points is {round(dist, 2)} units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LineString from our Point objects\n",
    "line = LineString([point1, point2, point3])\n",
    "\n",
    "# It is also possible to produce the same outcome using coordinate tuples\n",
    "line2 = LineString([(2.2, 4.2), (7.2, -25.1), (9.26, -2.456)])\n",
    "\n",
    "# Check if lines are identical\n",
    "line == line2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(line.coords))\n",
    "print(line.length)\n",
    "print(line.centroid)\n",
    "print(line.xy)\n",
    "print(line.xy[0]) \n",
    "print(line.xy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Polygon from the coordinates\n",
    "poly = Polygon([(2.2, 4.2), (7.2, -25.1), (9.26, -2.456)])\n",
    "\n",
    "poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Polygon based on information from the Shapely points\n",
    "poly2 = Polygon([[p.x, p.y] for p in [point1, point2, point3]])\n",
    "poly2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly == poly2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the outer border\n",
    "border = [(-180, 90), (-180, -90), (180, -90), (180, 90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer polygon\n",
    "world = Polygon(shell=border)\n",
    "print(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polygon attributes and functions¶\n",
    "We can again access different attributes directly from the `Polygon` object itself that can be really useful for many analyses, such as `area`, `centroid`, bounding box (`bounds`), `exterior`, and exterior-length (`exterior.length`). \n",
    "\n",
    "Here, we can see a few of the available attributes and how to access them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the outputs\n",
    "print(f\"Polygon centroid: {world.centroid}\")\n",
    "print(f\"Polygon Area: {world.area}\")\n",
    "print(f\"Polygon Bounding Box: {world.bounds}\")\n",
    "print(f\"Polygon Exterior: {world.exterior}\")\n",
    "print(f\"Polygon Exterior Length: {world.exterior.length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"geometrycollections\"></a>\n",
    "## Geometry collections\n",
    "In some occassions it is useful to store multiple geometries (e.g., several points or several polygons) in a single feature. For example, when country is composed of several islands, the polygons share the same attributes on the country-level and it might be reasonable to store that country as geometry collection that contains all the polygons. The attribute table would then contain one row of information with country-level attributes, and the geometry related to those attributes would represent several polygons.\n",
    "\n",
    "In Shapely, collections of `Point`s are implemented by using a `MultiPoint` object, collections of `LineString`s by using a `MultiLineString` object, and collections of `Polygon`s by a `MultiPolygon` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, LineString, Polygon\n",
    "from shapely.geometry import MultiPoint, MultiLineString, MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point1, point2, point3 = (2.2, 4.2), (7.2, -25.1), (9.26, -2.456)\n",
    "    \n",
    "# Create a MultiPoint object of our points 1,2 and 3\n",
    "multi_point = MultiPoint([point1, point2, point3])\n",
    "\n",
    "# It is also possible to pass coordinate tuples inside\n",
    "multi_point2 = MultiPoint([(2.2, 4.2), (7.2, -25.1), (9.26, -2.456)])\n",
    "\n",
    "# We can also create a MultiLineString with two lines\n",
    "line1 = LineString([point1, point2])\n",
    "line2 = LineString([point2, point3])\n",
    "multi_line = MultiLineString([line1, line2])\n",
    "\n",
    "# Print object definitions\n",
    "print(multi_point)\n",
    "print(multi_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MultiPolygon`s are constructed in a similar manner. Let’s create a bounding box for “the world” by combining two separate polygons that represent the western and eastern hemispheres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the exterior of the western part of the world\n",
    "west_exterior = [(-180, 90), (-180, -90), (0, -90), (0, 90)]\n",
    "\n",
    "# Let's create a hole --> remember there can be multiple holes, thus we need to have a list of hole(s). \n",
    "# Here we have just one.\n",
    "west_hole = [[(-170, 80), (-170, -80), (-10, -80), (-10, 80)]]\n",
    "\n",
    "# Create the Polygon\n",
    "west_poly = Polygon(shell=west_exterior, holes=west_hole)\n",
    "\n",
    "# Print object definition\n",
    "print(west_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapely also has a tool for creating a bounding box based on minimum and maximum $x$ and $y$ coordinates. Instead of using the `Polygon` constructor, let’s use the box constructor for creating the polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the bbox extent (lower-left corner coordinates and upper-right corner coordinates)\n",
    "min_x, min_y = 0, -90\n",
    "max_x, max_y = 180, 90\n",
    "\n",
    "# Create the polygon using Shapely\n",
    "east_poly = box(minx=min_x, miny=min_y, maxx=max_x, maxy=max_y)\n",
    "\n",
    "# Print object definition\n",
    "print(east_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "east_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can combine the two polygons into a `MultiPolygon`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create our MultiPolygon. We can pass multiple Polygon -objects into our MultiPolygon as a list\n",
    "multi_poly = MultiPolygon([west_poly, east_poly])\n",
    "\n",
    "# Print object definition\n",
    "print(multi_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if we have a \"valid\" `MultiPolygon`, i.e., if the individual polygons does notintersect with each other. Here, because the polygons have a common 0-meridian, we should NOT have a valid polygon. \n",
    "\n",
    "We can check the validity of an object from the `is_valid` attribute that tells if the polygons or lines intersect with each other. This can be really useful information when trying to find topological errors from your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Is polygon valid? {multi_poly.is_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"geopandas\"></a>\n",
    "# Geopandas\n",
    "\n",
    "[**Geopandas**](http://geopandas.org/) makes it possible to work with geospatial data in Python in a relatively easy way. Geopandas combines the capabilities of the data analysis library pandas with other packages like Shapely and fiona for managing spatial data.\n",
    "\n",
    "The main data structures in geopandas are `GeoSeries` and `GeoDataFrame` which extend the capabilities of `Series` and `DataFrame`s from pandas. This means that we can use all our pandas skills also when working with geopandas!\n",
    "\n",
    "The main difference between `GeoDataFrame`s and pandas `DataFrame`s is that a `GeoDataFrame` should contain one column for geometries. By default, the name of this column is `'geometry'`. The geometry column is a `GeoSeries` which contains the geometries (`Point`, `LineString`, `Polygon`) as shapely objects.\n",
    "\n",
    "![](https://autogis-site.readthedocs.io/en/latest/_images/geodataframe.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"readingshapefile\"></a>\n",
    "## Reading a Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"data/L2_data/NLS/2018/L4/L41/L4132R.shp/m_L4132R_p.shp\"\n",
    "# Read file using gpd.read_file()\n",
    "data = gpd.read_file(fp)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might guess, the column names are in Finnish. Let’s select only the useful columns and rename them into English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['RYHMA', 'LUOKKA',  'geometry']]\n",
    "colnames = {'RYHMA':'GROUP', 'LUOKKA':'CLASS'}\n",
    "data.rename(columns=colnames, inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that our data variable is a `GeoDataFrame`. `GeoDataFrame` extends the functionalities of `pandas.DataFrame` in a way that it is possible to handle spatial data using similar approaches and datastructures as in pandas (hence the name geopandas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good idea to explore your data also on a map. Creating a simple map from a GeoDataFrame is really easy: you can use `.plot()` function from geopandas that creates a map based on the geometries of the data. Geopandas actually uses matplotlib for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the data\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "data.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"geometriesgeopandas\"></a>\n",
    "## Geometries in Geopandas\n",
    "Geopandas takes advantage of Shapely’s geometric objects. Geometries are stored in a column called geometry that is a default column name for storing geometric information in geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['geometry'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geometry column contains familiar looking values, namely Shapely `Polygon` objects. Since the spatial data is stored as Shapely objects, it is possible to use Shapely methods when dealing with geometries in geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the geometry on the first row of data\n",
    "data.at[0, \"geometry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information about the area \n",
    "print(\"Area:\", round(data.at[0, \"geometry\"].area, 0), \"square meters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the GeoDataFrame rows using the `iterrows()` function. For each row, print the area of the polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in data.iterrows():\n",
    "    area = row['geometry'].area\n",
    "    print(\"Area:\", round(area, 0), \"square meters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see from here, all pandas methods, such as the `iterrows()` function, are directly available in Geopandas without the need to call pandas separately because Geopandas is an extension for pandas.\n",
    "\n",
    "In practice, it is not necessary to use the `iterrows()` approach to calculate the area for all features. Geodataframes and geoseries have an attribute area which we can use for accessing the area for each feature at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"writingdata\"></a>\n",
    "## Writing data into a shapefile\n",
    "It is possible to export `GeoDataFrame`s into various data formats using the `to_file()` method. In our case, we want to export subsets of the data into Shapefiles (one file for each feature class).\n",
    "\n",
    "Let’s first select one class (class number 36200, “Lake water”) from the data as a new `GeoDataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a class\n",
    "selection = data[data[\"CLASS\"]==36200]\n",
    "selection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = plt.axes()\n",
    "selection.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write this layer into a new Shapefile using the `gpd.to_file()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a output path for the data\n",
    "output_fp = \"created_files/Class_36200.shp\"\n",
    "\n",
    "# Create the  folder if it does not exist\n",
    "if not os.path.exists('created_files'):\n",
    "    os.makedirs('created_files')\n",
    "\n",
    "# Write those rows into a new file (the default output file format is Shapefile)\n",
    "selection.to_file(output_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sjoins'></a>\n",
    "## Spatial joins\n",
    "A **spatial join** uses binary predicates such as `intersects` and `crosses` to combine two `GeoDataFrame`s based on the spatial relationship between their geometries.\n",
    "\n",
    "A common use case might be a spatial join between a `Point` and a `Polygon` where you want to retain the point geometries and grab the attributes of the intersecting polygons.\n",
    "\n",
    "![](https://web.natur.cuni.cz/~langhamr/lectures/vtfg1/mapinfo_1/about_gis/Image23.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of spatial joins\n",
    "Geopandas currently supports the following methods of spatial joins. We refer to the `left_df` and `right_df` which are the correspond to the two dataframes passed in as arguments.\n",
    "\n",
    "#### Left outer join\n",
    "In a LEFT OUTER JOIN (`how='left'`), we keep all rows from the left and duplicate them if necessary to represent multiple hits between the two dataframes. We retain attributes of the right if they intersect and lose right rows that do not intersect. A left outer join implies that we are interested in retaining the geometries of the left.\n",
    "\n",
    "#### Right outer join\n",
    "In a RIGHT OUTER JOIN (`how='right'`), we keep all rows from the right and duplicate them if necessary to represent multiple hits between the two dataframes. We retain attributes of the left if they intersect and lose left rows that don’t intersect. A right outer join implies that we are interested in retaining the geometries of the right.\n",
    "\n",
    "#### Inner join\n",
    "In an INNER JOIN (`how='inner'`), we keep rows from the right and left only where their binary predicate is `True`. We duplicate them if necessary to represent multiple hits between the two dataframes. We retain attributes of the right and left only if they intersect and lose all rows that do not. An inner join implies that we are interested in retaining the geometries of the left.\n",
    "\n",
    "![](https://www.golinuxcloud.com/wp-content/uploads/types_joins.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC Boros\n",
    "zippath = gpd.datasets.get_path('nybb')\n",
    "polydf = gpd.read_file(zippath)\n",
    "polydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "polydf.plot(ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polydf_lat_lng = polydf.to_crs(epsg=4326)\n",
    "\n",
    "polydf_lat_lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polydf_lat_lng.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polydf.total_bounds\n",
    "# tuple containing minx, miny, maxx, maxy values \n",
    "# for the bounds of the series as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some points\n",
    "b = [int(x) for x in polydf.total_bounds]\n",
    "N = 8\n",
    "pointdf = gpd.GeoDataFrame([\n",
    "    {'geometry': Point(x, y), 'value1': x + y, 'value2': x - y}\n",
    "    for x, y in zip(range(b[0], b[2], int((b[2] - b[0]) / N)),\n",
    "                    range(b[1], b[3], int((b[3] - b[1]) / N)))])\n",
    "\n",
    "# Make sure they're using the same projection reference\n",
    "pointdf.crs = polydf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "ax = plt.axes()\n",
    "ax = polydf.plot(ax = ax) \n",
    "ax = pointdf.plot(ax=ax, color='r')\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_left_df = pointdf.sjoin(polydf, how=\"left\")\n",
    "join_left_df\n",
    "# Note the NaNs where the point did not intersect a boro\n",
    "# Note that the default join predicate is 'intersects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_left_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_inner_df = pointdf.sjoin(polydf, how=\"inner\")\n",
    "join_inner_df\n",
    "# Note the lack of NaNs; dropped anything that didn't intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_inner_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re not limited to using the `intersection` binary predicate. Any of the Shapely geometry methods that return a Boolean can be used by specifying the op kwarg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointdf.sjoin(polydf, how=\"left\", predicate=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "-Retrieve the shapefile of italian regions\n",
    "\n",
    "-Retrieve the list of italian regional capitals, with coordinates\n",
    "\n",
    "-Assign the correct capital to each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "capitals_df = pd.read_csv('data/italian_regional_capitals.csv')\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "capitals_gdf = gpd.GeoDataFrame(capitals_df,geometry=gpd.points_from_xy(capitals_df.longitude, capitals_df.latitude)\n",
    ")\n",
    "\n",
    "capitals_df.crs = \"EPSG:4326\"\n",
    "\n",
    "capitals_gdf.drop(['latitude', 'longitude', 'region'], axis=1, inplace=True)\n",
    "\n",
    "capitals_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_gdf = gpd.read_file(\"data/it.json\")\n",
    "\n",
    "region_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_gdf.crs = capitals_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = capitals_gdf.sjoin(region_gdf, how=\"left\", predicate=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.dropna()\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "region_gdf.plot(ax=ax, color='white', edgecolor='black')\n",
    "joined_df.plot(ax=ax, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "capitals_df = pd.read_csv('data/italian_regional_capitals.csv')\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "capitals_gdf = gpd.GeoDataFrame(capitals_df,geometry=gpd.points_from_xy(capitals_df.longitude, capitals_df.latitude)\n",
    ")\n",
    "\n",
    "capitals_df.crs = \"EPSG:4326\"\n",
    "\n",
    "print(capitals_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_gdf = gpd.read_file(\"data/it.json\")\n",
    "\n",
    "region_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_gdf.crs = capitals_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = capitals_gdf.sjoin(region_gdf, how=\"left\", predicate=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "\n",
    "region_gdf.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "joined_df.plot(ax=ax, color='red', markersize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "\n",
    "region_gdf.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "capitals_gdf.plot(ax=ax, color='red', markersize=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scikitmobility\"></a>\n",
    "# scikit-mobility\n",
    "\n",
    "![GitHub Repo stars](https://img.shields.io/github/stars/scikit-mobility/scikit-mobility?style=social)\n",
    "![GitHub](https://img.shields.io/github/license/scikit-mobility/scikit-mobility)\n",
    "![GitHub release (latest by date)](https://img.shields.io/github/v/release/scikit-mobility/scikit-mobility)\n",
    "\n",
    "[**scikit-mobility**](https://github.com/scikit-mobility/scikit-mobility) is a python library that provides scientists and practitioners with an environment to:\n",
    "\n",
    "1. load and represent mobility data, both at the individual and the collective level, through easy-to-use data structures\n",
    "(`TrajDataFrame` and `FlowDataFrame`); \n",
    "2. visualize trajectories and flows on interactive maps;\n",
    "3. clean and preprocess mobility data using state-of-the-art techniques, such as trajectory clustering, compression, segmentation, and filtering;\n",
    "4. analyze mobility data by using the main measures characterizing mobility patterns both at the individual and at the collective level, such as the computation of travel and characteristic distances, object and location entropies, location frequencies, waiting times, origin-destination matrices, and more;\n",
    "4. run the most popular mechanistic generative models to simulate individual mobility, such as the Exploration and Preferential Return model (EPR) and its variants, and commuting and migratory flows, such as the Gravity\n",
    "Model and the Radiation Model;\n",
    "5. estimate the privacy risk associated with the analysis of a given mobility dataset through the simulation of the reidentification risk associated with a vast repertoire of privacy attacks.\n",
    "\n",
    "- scikit-mobility is publicly available on GitHub at the following link: https://scikit-mobility.github.io/scikit-mobility/. \n",
    "\n",
    "- the documentation describing all the classes and functions of scikit-mobility\n",
    "is available at https://scikit-mobility.github.io/scikit-mobility/.\n",
    "\n",
    "The paper describing scikit-mobility may be found at: https://www.jstatsoft.org/article/view/v103i04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "import skmob\n",
    "\n",
    "skmob.__version__\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"datastructures\"></a>\n",
    "## Data Structures\n",
    "\n",
    "scikit-mobility provides two data structures to deal with raw trajectories and flows between places: \n",
    "- `TrajDataFrame`, for spatio-temporal trajectories; \n",
    "- `FlowDataFrame`, for mobility flows.\n",
    "\n",
    "Both the data structures are an extension of the DataFrame implemented in the data analysis library [pandas](https://pandas.pydata.org/). Thus, both `TrajDataFrame`\n",
    "and `FlowDataFrame` inherit all the functionalities provided by the `DataFrame` as well as all the efficient optimizations for reading and writing tabular data (e.g., mobility datasets). \n",
    "\n",
    "The current version of the library is designed to work with the latitude and longitude system (`epsg:4326`). Therefore, the Haversine formula is used by default when the library’s functions compute distances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trajdataframe\"></a>\n",
    "### The `TrajDataFrame`\n",
    "\n",
    "Mobility data describe the movements of a set of objects during a period of observation. The objects may represent individuals, private vehicles, boats, and even players on a sports field. \n",
    "\n",
    "Mobility data are generally collected in an automatic way as a by-product of human activity on electronic devices (e.g., mobile phones, GPS devices, social\n",
    "networking platforms, video cameras) and stored as trajectories, a temporally ordered sequence of spatio-temporal points where an object stopped in or went through. \n",
    "\n",
    "A `TrajDataFrame` is an extension of the pandas DataFrame that has specific columns names and data types. Each row in a `TrajDataFrame` describes a trajectory's point and contains the following columns:\n",
    "\n",
    "- `lat` - latitude of the point\n",
    "- `lng` - longitude of the point\n",
    "- `datetime` - date and time of the point\n",
    "\n",
    "For multi-user data sets, there are two optional columns:\n",
    "\n",
    "- `uid` - user's identifier to which the trajectory belongs to\n",
    "- `tid` - identifier for the trajectory\n",
    "\n",
    "\n",
    "#### Creating a `TrajDataFrame`\n",
    "\n",
    "A `TrajDataFrame` can be created from:\n",
    "\n",
    "- a python list or numpy array\n",
    "- a python dictionary\n",
    "- a pandas DataFrame\n",
    "- a text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From a python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a list\n",
    "data_list = [[1, 39.984094, 116.319236, '2008-10-23 13:53:05'],\n",
    "             [1, 39.984198, 116.319322, '2008-10-23 13:53:06'],\n",
    "             [1, 39.984224, 116.319402, '2008-10-23 13:53:11'],\n",
    "             [1, 39.984211, 116.319389, '2008-10-23 13:53:16']]\n",
    "data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must set the indexes of the mandatory columns using arguments `latitude`, `longitude` and `datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = skmob.TrajDataFrame(data_list, \n",
    "                          latitude=1, longitude=2, \n",
    "                          datetime=3)\n",
    "print(type(tdf))\n",
    "tdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dataframe from the 2D list\n",
    "data_df = pd.DataFrame(data_list, columns=['user', 'lat', 'lng', 'hour'])\n",
    "print(type(data_df)) # type of the structure\n",
    "data_df.head() # head of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "\n",
    "- the name of columns in `data_df` do not match the names required\n",
    "- you must specify the names of the mandatory columns using arguments `latitude`, `longitude` and `datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TrajDataFrame from a DataFrame\n",
    "tdf = skmob.TrajDataFrame(data_df, datetime='hour', user_id='user', latitude='lat', longitude='lng')\n",
    "print(type(tdf))\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of a `TrajDataFrame` have specific types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the DataFrame\n",
    "print(type(data_df))\n",
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tdf)) # In the TrajDataFrame\n",
    "tdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['lat'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From an URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a TrajDataFrame from a dataset of trajectories \n",
    "url = \"https://github.com/scikit-mobility/tutorials/raw/master/mda_masterbd2020/data/geolife_sample.txt.gz\"\n",
    "tdf = skmob.TrajDataFrame.from_file(url)\n",
    "print(type(tdf))\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attributes of a TrajDataFrame\n",
    "- `crs`: the coordinate reference system. Default: epsg:4326 (lat/long)\n",
    "- `parameters`: dictionary to add as many as necessary additional properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wsg84 datum\n",
    "print(tdf.crs)\n",
    "print(tdf.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your own parameter\n",
    "tdf.parameters['analyzed'] = 1\n",
    "tdf.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualizing a `TrajDataFrame`\n",
    "tdf.plot_trajectory(hex_color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tessellation\"></a>\n",
    "### Tessellation\n",
    "In mobility tasks, the geography is often discretized by mapping the coordinates to a *tessellation*, i.e., a covering of the\n",
    "bi-dimensional space using a countable number of geometric shapes (e.g., squares, hexagons), called tiles, with no overlaps\n",
    "and no gaps. \n",
    "\n",
    "For instance, for the analysis or prediction of mobility flows, a spatial tessellation is used to aggregate flows of people moving among locations (the tiles of the tessellation). \n",
    "\n",
    "#### Creating tessellations given a city name and a tile size\n",
    "\n",
    "##### Squared tessellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmob.tessellation.tilers import tiler\n",
    "from skmob.utils.plot import plot_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_squared = tiler.get('squared', base_shape='Florence, Italy', meters=1000)\n",
    "print(\"tiles = %s\" %len(tess_squared))\n",
    "tess_squared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gdf(tess_squared, zoom=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_squared = tiler.get('squared', base_shape='Florence, Italy', meters=200)\n",
    "print(\"tiles = %s\" %len(tess_squared))\n",
    "tess_squared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gdf(tess_squared, zoom=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hexagonal tessellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_h3 = tiler.get('h3_tessellation', base_shape='Florence, Italy', meters=1000)\n",
    "print(\"tiles = %s\" %len(tess_h3))\n",
    "tess_h3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gdf(tess_h3, zoom=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_h3 = tiler.get('h3_tessellation', base_shape='Florence, Italy', meters=200)\n",
    "print(\"tiles = %s\" %len(tess_h3))\n",
    "tess_h3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gdf(tess_h3, zoom=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"flowdataframe\"></a>\n",
    "### The `FlowDataFrame`\n",
    "\n",
    "Origin-destination matrices, aka *flows*, are another common representation of mobility data. While trajectories refer to movements of single objects, flows refer to aggregated movements of objects between a set of locations. An example of flows is the daily commuting flows between the neighbourhoods of a city.\n",
    "\n",
    "In scikit-mobility, an origin-destination matrix is described by a `FlowDataFrame`, an extension of the pandas DataFrame that has specific column names and data types. \n",
    "\n",
    "A row in a `FlowDataFrame` represents a flow of objects between two locations, described by three mandatory columns: \n",
    "- `origin` (any type), \n",
    "- `destination` (any type),\n",
    "- `flow` (type: integer). \n",
    "\n",
    "In mobility tasks, the geography is often discretized by mapping the coordinates to a *tessellation*, i.e., a covering of the\n",
    "bi-dimensional space using a countable number of geometric shapes (e.g., squares, hexagons), called tiles, with no overlaps\n",
    "and no gaps. \n",
    "\n",
    "For instance, for the analysis or prediction of mobility flows, a spatial tessellation is used to aggregate flows of people moving among locations (the tiles of the tessellation). \n",
    "\n",
    "For this reason, each `FlowDataFrame` is associated with a spatial tessellation, a [geopandas](https://geopandas.org/) GeoDataFrame that contains two mandatory columns: \n",
    "- `tile_ID` (any type) indicates the identifier of\n",
    "a location; \n",
    "- `geometry` indicates the geometric shape that describes the location on a territory (e.g., a square, an hexagon, the shape of a neighborhood).\n",
    "\n",
    "Each location identifier in the origin and destination columns of a `FlowDataFrame` must be present in the associated spatial tessellation. Otherwise, the library raises an exception. \n",
    "\n",
    "Similarly, scikit-mobility raises an exception if the type of the `origin` and `destination` columns in the `FlowDataFrame` and the type of\n",
    "the `tile_ID` column in the associated tessellation are different.\n",
    "\n",
    "#### Creating a `FlowDataFrame`\n",
    "\n",
    "Each `FlowDataFrame` goes in companion with a spatial tessellation. So, we must first create/upload a spatial tessellation, which as geopandas GeoDataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/scikit-mobility/tutorials/master/mda_masterbd2020/data/NY_counties_2011.geojson\"\n",
    "tessellation = gpd.read_file(url) # load a tessellation\n",
    "tessellation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gdf(tessellation, zoom=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation = tessellation.explode()\n",
    "plot_gdf(tessellation, zoom=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tip\n",
    "Once you have a `GeoDataFrame` or a `GeoSeries` (i.e., just the `geometry` column), you can construct a squared tessellation on it.\n",
    "(There's a bug instead for the h3 tessellation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_tess_squared = tiler.get('squared', base_shape=tessellation, meters=10000)\n",
    "print(\"tiles = %s\" %len(ny_tess_squared))\n",
    "ny_tess_squared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gdf(ny_tess_squared, zoom=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can create a `FlowDataFrame` from a file/url, specifying the spatial tessellation it refers to using argument `tessellation`. \n",
    "\n",
    "Also, you must specify the name of the column in the tessellation `GeoDataFrame` containing the identifier of the locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/scikit-mobility/tutorials/raw/master/mda_masterbd2020/data/NY_commuting_flows_2011.csv\"\n",
    "fdf = skmob.FlowDataFrame.from_file(url, tessellation=tessellation, tile_id='tile_id')\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.tessellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the spatial tessellation associated with the created `FlowDataFrame` using the attribute `.tessellation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tessellation is an attribute of the FlowDataFrame\n",
    "fdf.tessellation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf['origin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation['tile_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.plot_flows(tiles = 'cartodbpositron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.plot_tessellation(tiles = 'cartodbpositron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_f = fdf.plot_tessellation(tiles='cartodbpositron')\n",
    "fdf.plot_flows(map_f=map_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download your mobility data from https://takeout.google.com/\n",
    "\n",
    "-Create and visualize you tdf\n",
    "\n",
    "-Create your personal flow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Takeout/2022_OCTOBER.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['timelineObjects'][2].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['timelineObjects'][2]['placeVisit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_visits = []\n",
    "\n",
    "for item in data.get('timelineObjects', []):\n",
    "\n",
    "    if 'placeVisit' in item:\n",
    "        visit = item['placeVisit']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_visits = []\n",
    "\n",
    "for item in data.get('timelineObjects', []):\n",
    "\n",
    "    if 'placeVisit' in item:\n",
    "        visit = item['placeVisit']\n",
    "        \n",
    "        # Extract relevant details from the place visit\n",
    "        location = visit.get('location', {})\n",
    "        lat = location.get('latitudeE7', 0) / 1e7\n",
    "        lon = location.get('longitudeE7', 0) / 1e7\n",
    "        name = location.get('name', 'Unknown Place')\n",
    "        address = location.get('address', 'Unknown Address')\n",
    "        place_id = location.get('placeId', 'N/A')\n",
    "        \n",
    "        # Extract visit duration details\n",
    "        start_timestamp = visit['duration'].get('startTimestamp')\n",
    "        end_timestamp = visit['duration'].get('endTimestamp')\n",
    "        \n",
    "        # Convert timestamps to datetime format\n",
    "        if start_timestamp:\n",
    "            start_timestamp = datetime.fromisoformat(start_timestamp.replace(\"Z\", \"+00:00\"))\n",
    "        if end_timestamp:\n",
    "            end_timestamp = datetime.fromisoformat(end_timestamp.replace(\"Z\", \"+00:00\"))\n",
    "        \n",
    "        # Append place visit data to the list\n",
    "        place_visits.append([1, lat, lon, start_timestamp, end_timestamp, name, address, place_id])\n",
    "\n",
    "\n",
    "# Create a DataFrame from the extracted place visit data\n",
    "df = pd.DataFrame(place_visits, columns=['Uid', 'lat', 'lon', 'start_timestamp', 'end_timestamp', 'name', 'address', 'place_id'])\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a TrajDataFrame from the DataFrame\n",
    "\n",
    "tdf = skmob.TrajDataFrame(df, datetime='start_timestamp', user_id='Uid', latitude='lat', longitude='lon')\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.plot_trajectory(hex_color='red', zoom=10, weight=2, tiles='cartodbpositron', max_points=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acitivity_Segments = []\n",
    "\n",
    "for item in data.get('timelineObjects', []):\n",
    "\n",
    "    if 'activitySegment' in item:\n",
    "        visit = item['activitySegment']\n",
    "        \n",
    "        # Extract relevant details from the place visit\n",
    "        location = visit.get('startLocation', {})\n",
    "        lat = location.get('latitudeE7', 0) / 1e7\n",
    "        lon = location.get('longitudeE7', 0) / 1e7\n",
    "        name = location.get('name', 'Unknown Place')\n",
    "        address = location.get('address', 'Unknown Address')\n",
    "        place_id = location.get('placeId', 'N/A')\n",
    "        \n",
    "        # Extract visit duration details\n",
    "        start_timestamp = visit['duration'].get('startTimestamp')\n",
    "        end_timestamp = visit['duration'].get('endTimestamp')\n",
    "        \n",
    "        # Convert timestamps to datetime format\n",
    "        if start_timestamp:\n",
    "            start_timestamp = datetime.fromisoformat(start_timestamp.replace(\"Z\", \"+00:00\"))\n",
    "        if end_timestamp:\n",
    "            end_timestamp = datetime.fromisoformat(end_timestamp.replace(\"Z\", \"+00:00\"))\n",
    "        \n",
    "        # Append place visit data to the list\n",
    "        acitivity_Segments.append([1, lat, lon, start_timestamp, end_timestamp, name, address, place_id])\n",
    "\n",
    "\n",
    "# Create a DataFrame from the extracted place visit data\n",
    "df = pd.DataFrame(acitivity_Segments, columns=['Uid', 'lat', 'lon', 'start_timestamp', 'end_timestamp', 'name', 'address', 'place_id'])\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = skmob.TrajDataFrame(df, datetime='start_timestamp', user_id='Uid', latitude='lat', longitude='lon')\n",
    "\n",
    "tdf.plot_trajectory(hex_color='red', zoom=10, weight=2, tiles='cartodbpositron', max_points=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skmob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
