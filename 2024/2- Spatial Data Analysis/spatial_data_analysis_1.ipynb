{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79dd6e2b",
   "metadata": {},
   "source": [
    "Author: Mirco Nanni\n",
    "\n",
    "Geospatial Analytics, Master degree in Data Science and Business Informatics, University of Pisa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657de7ec",
   "metadata": {},
   "source": [
    "# Geospatial Analytics - Lesson 3: Spatial Data Analysis\n",
    "\n",
    "Topics covered:\n",
    "* [Density](#density) and [kernel density](#kernel)\n",
    "* [ANN analysis](#ann) and [L-function](#l-function)\n",
    "* [Spatial autocorrelation](#autocorrelation) (Moran's I and Geary's C)\n",
    "* [Interpolation with IDW](#idw)\n",
    "* [Kriging](#kriging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16b400",
   "metadata": {},
   "source": [
    "\n",
    "|Task  | Method | Ad hoc library | Is in these exercises? |\n",
    "| --- | --- | --- | --- |\n",
    "|Density| Basic | *none* | Yes |\n",
    "|| Kernel | *none* | Yes |\n",
    "|Point patterns | Average Nearest Neighbor | *none* | Yes |\n",
    "|| L-function | *none* | Yes |\n",
    "|Autocorrelation| Moran's I | pysal | Yes |\n",
    "|| Geary's C| pysal | Yes |\n",
    "|Interpolation| Thiessen polygons| - | - |\n",
    "||Inverse Distance Weighted| KNeighborsRegressor | Yes |\n",
    "||Trend surface| - | - |\n",
    "||Kriging|pykrige | Yes |\n",
    "|Regression| Exogenous/Endogenous regressors| - | - |\n",
    "|Associations|Co-location patterns| - | - |\n",
    "|Trends|Spatial Trends detection| - | - |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3b09c7",
   "metadata": {},
   "source": [
    "<a id='density'></a>\n",
    "# Density measures\n",
    "Adapted from https://pygis.io/docs/e_summarize_vector.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b9f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import geopandas as gpd\n",
    "import geoplot as gplt\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "from scipy import stats\n",
    "from shapely.geometry import Polygon, box\n",
    "from sklearn.datasets import fetch_species_distributions\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598095f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# source: ISTAT - https://www.istat.it/storage/cartografia/confini_amministrativi/generalizzati/2024/Limiti01012024_g.zip\n",
    "regions = gpd.read_file(\"data/Limiti01012024_g/Reg01012024_g/Reg01012024_g_WGS84.shp\")\n",
    "tuscany = regions[regions['DEN_REG']=='Toscana'].to_crs('EPSG:4326')\n",
    "\n",
    "df = pd.read_csv(\"data/EV_stations.csv\")\n",
    "EVS = gpd.GeoDataFrame(\n",
    "    geometry=gpd.points_from_xy(df.lon, df.lat, crs=\"EPSG:4326\"), data=df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e81cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuscany.plot()\n",
    "EVS.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2850a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(feature, side_length):\n",
    "    # Get extent of buffered input feature\n",
    "    min_x, min_y, max_x, max_y = feature.total_bounds\n",
    "    print(\"Bbox: \", min_x, min_y, max_x, max_y)\n",
    "\n",
    "    # Create empty list to hold individual cells that will make up the grid\n",
    "    cells_list = []\n",
    "\n",
    "    for x in np.arange(min_x - side_length, max_x + side_length, side_length):\n",
    "        for y in np.arange(min_y - side_length, max_y + side_length, side_length):\n",
    "            # Create a box with specified side length and append to list\n",
    "            cells_list.append(box(x, y, x + side_length, y + side_length))\n",
    "    # Create grid from list of cells\n",
    "    grid = gpd.GeoDataFrame(cells_list, columns = ['geometry'], crs = \"EPSG:4326\")\n",
    "\n",
    "    # Create a column that assigns each grid a number\n",
    "    grid[\"Grid_ID\"] = np.arange(len(grid))\n",
    "\n",
    "    # Return grid\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c349c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = create_grid(tuscany, 0.1)\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "tuscany.plot(ax = ax, color = 'bisque', edgecolor = 'dimgray')\n",
    "EVS.plot(ax = ax, marker = 'o', color = 'dodgerblue', markersize = 3)\n",
    "grid.plot(ax = ax, color = 'none', edgecolor = 'lightseagreen', alpha = 0.55)\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Tuscany - Boundaries, EV stations, and Grids', fontdict = {'fontsize': '15', 'fontweight' : '3'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ecfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a INNER - INTERSECT spatial join\n",
    "EVS_cells = gpd.sjoin(EVS, grid, how = \"inner\", op = \"intersects\")\n",
    "\n",
    "# Remove duplicate counts\n",
    "# With intersect, those that fall on a boundary will be allocated to all cells that share that boundary\n",
    "EVS_cells = EVS_cells.drop_duplicates(subset = ['ID']).reset_index(drop = True)\n",
    "\n",
    "# Set field name to hold count value\n",
    "count_field = \"Count\"\n",
    "\n",
    "# Add a field with constant value of 1\n",
    "EVS_cells[count_field] = 1\n",
    "\n",
    "# Group GeoDataFrame by cell while aggregating the Count values\n",
    "EVS_cells = EVS_cells.groupby('Grid_ID').agg({count_field:'sum'})\n",
    "\n",
    "# Merge the resulting grouped dataframe with the grid GeoDataFrame, using a left join to keep all cell polygons\n",
    "grid = grid.merge(EVS_cells, on = 'Grid_ID', how = \"left\")\n",
    "\n",
    "# Fill the NaN values (cells without any points) with 0\n",
    "grid[count_field] = grid[count_field].fillna(0)\n",
    "\n",
    "# Convert Count field to integer\n",
    "grid[count_field] = grid[count_field].astype(int)\n",
    "\n",
    "# Display grid attribute table\n",
    "display(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8baee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "grid['logCount'] = np.log(grid['Count']+1)  # to make log colormap\n",
    "\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "tuscany.plot(ax = ax, color = 'none', edgecolor = 'dimgray')\n",
    "EVS.plot(ax = ax, marker = 'o', color = 'dimgray', markersize = 3)\n",
    "grid.plot(ax = ax, column = \"logCount\", cmap = \"RdPu\", edgecolor = 'lightseagreen', linewidth = 0.5, alpha = 0.70, legend = True)\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Tuscany - Binning EVS Points', fontdict = {'fontsize': '15', 'fontweight' : '3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b93cf24",
   "metadata": {},
   "source": [
    "<a id='kernel'></a>\n",
    "# Simple Kernel Density\n",
    "Adopt uniform weights and 8-cell neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the two grids and aggregate counts\n",
    "grid2 = gpd.GeoDataFrame(grid.to_crs('EPSG:3003').buffer(2000).to_crs('EPSG:4326'), geometry=0)\n",
    "grid2[\"Grid2_ID\"] = np.arange(len(grid2))\n",
    "# Each cell in grid2 captures the 8-cell neighborhood of the original cell\n",
    "grid2 = gpd.sjoin(grid2, grid, how = \"left\", predicate = \"intersects\")\n",
    "# Sum up the densities of the neihborhood\n",
    "grid2 = grid2.groupby('Grid2_ID').agg({'Count':'sum'}).reset_index().rename(columns={'Grid2_ID':'Grid_ID'})\n",
    "grid2 = gpd.GeoDataFrame(grid2.merge(grid, on = 'Grid_ID', how = \"left\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96347a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2['logCount'] = np.log(grid2['Count_x']+1)\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "tuscany.plot(ax = ax, color = 'none', edgecolor = 'dimgray')\n",
    "EVS.plot(ax = ax, marker = 'o', color = 'dimgray', markersize = 3)\n",
    "grid2.plot(ax = ax, column = \"logCount\", cmap = \"RdPu\", edgecolor = 'lightseagreen', linewidth = 0.5, alpha = 0.70, legend = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761182dc",
   "metadata": {},
   "source": [
    "<a id='ann'></a>\n",
    "# Average Nearest Neighbor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def average_nearest_neighbor_distance(gdf, proj=None):\n",
    "    # Ensure the geometry column contains Points\n",
    "    if not all(gdf.geometry.type == 'Point'):\n",
    "        raise ValueError(\"The GeoDataFrame should only contain Point geometries.\")\n",
    "    \n",
    "    # Convert WGS84 coordinates to a local projection (e.g., UTM) to get distances in meters\n",
    "    if proj == None:\n",
    "        proj = 3395  # World Mercator (EPSG:3395), or choose another local CRS for your region\n",
    "    gdf_projected = gdf.to_crs(epsg=proj)  \n",
    "\n",
    "    # Extract the x and y coordinates\n",
    "    coordinates = np.array([[geom.x, geom.y] for geom in gdf_projected.geometry])\n",
    "\n",
    "    # Use a KDTree for efficient nearest neighbor calculation\n",
    "    kdtree = cKDTree(coordinates)\n",
    "\n",
    "    # Query the nearest neighbor for each point (k=2 because the nearest neighbor of a point is itself)\n",
    "    distances, indices = kdtree.query(coordinates, k=2)\n",
    "\n",
    "    # The nearest neighbor distance for each point is the second column (ignoring self-distance)\n",
    "    nearest_neighbor_distances = distances[:, 1]\n",
    "\n",
    "    # Calculate the average of these nearest neighbor distances\n",
    "    avg_nearest_neighbor_distance = nearest_neighbor_distances.mean()\n",
    "\n",
    "    return avg_nearest_neighbor_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb80d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/EV_stations.csv\")\n",
    "EVS = gpd.GeoDataFrame(\n",
    "    geometry=gpd.points_from_xy(df.lon, df.lat, crs=\"EPSG:4326\"), data=df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_nearest_neighbor_distance(EVS, proj=3003)  # EPSG:3003 - Monte Mario / Italy zone 1 (https://epsg.io/3003)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94d73ba",
   "metadata": {},
   "source": [
    "<a id='l-function'></a>\n",
    "# Ripley's L-function L(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8de271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from scipy.spatial import cKDTree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ripley_L_function(gdf, distances, proj=None):\n",
    "    # Ensure the geometry column contains Points\n",
    "    if not all(gdf.geometry.type == 'Point'):\n",
    "        raise ValueError(\"The GeoDataFrame should only contain Point geometries.\")\n",
    "    \n",
    "    # Convert WGS84 coordinates to a local projection (e.g., UTM or World Mercator) to get distances in meters\n",
    "    if proj == None:\n",
    "        proj = 3395  # World Mercator (EPSG:3395), or choose another local CRS for your region\n",
    "    gdf_projected = gdf.to_crs(epsg=proj)\n",
    "\n",
    "    # Extract the coordinates of the points\n",
    "    coordinates = np.array([[geom.x, geom.y] for geom in gdf_projected.geometry])\n",
    "\n",
    "    # Get the area of the convex hull of the points (or another study area measure if provided)\n",
    "    area = gdf_projected.unary_union.convex_hull.area\n",
    "\n",
    "    # Total number of points\n",
    "    num_points = len(gdf)\n",
    "\n",
    "    # Use a KDTree for efficient distance calculation\n",
    "    kdtree = cKDTree(coordinates)\n",
    "\n",
    "    # Density of points\n",
    "    point_density = num_points / area\n",
    "\n",
    "    # Initialize an array to store L(d) values\n",
    "    L_values = np.zeros(len(distances))\n",
    "\n",
    "    # Iterate over each distance threshold\n",
    "    for i, d in enumerate(distances):\n",
    "        # Query for the number of neighbors within distance d for each point\n",
    "        counts = kdtree.query_ball_point(coordinates, r=d)\n",
    "\n",
    "        # Compute K(d) by summing the neighbors for each point, excluding the point itself\n",
    "        K_d = sum(len(c) - 1 for c in counts) / num_points\n",
    "\n",
    "        # Normalize by point density and area\n",
    "        K_d /= point_density\n",
    "\n",
    "        # Compute L(d)\n",
    "        L_values[i] = np.sqrt(K_d / np.pi)\n",
    "\n",
    "    return L_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c200021",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.linspace(0, 10000, 100)  # Define distance thresholds (0 to 1000 meters, 50 steps)\n",
    "L_values = ripley_L_function(EVS, distances, proj=3003) # EPSG:3003 - Monte Mario / Italy zone 1 (https://epsg.io/3003)\n",
    "\n",
    "# Plot the L-function\n",
    "plt.plot(distances, L_values)\n",
    "plt.xlabel('Distance (meters)')\n",
    "plt.ylabel('L(d)')\n",
    "plt.title('Ripley’s L-function')\n",
    "plt.plot(distances, distances, color='r', linestyle='--') # CSR reference line\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5586fd4",
   "metadata": {},
   "source": [
    "<a id='autocorrelation'></a>\n",
    "# Spatial Autocorrelation\n",
    "\n",
    "Source: https://geographicdata.science/book/notebooks/06_spatial_autocorrelation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c097b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from pysal.viz import splot\n",
    "from splot.esda import plot_moran\n",
    "import contextily\n",
    "\n",
    "# Analysis\n",
    "import geopandas\n",
    "import pandas\n",
    "from pysal.explore import esda\n",
    "from pysal.lib import weights\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281629c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://data.london.gov.uk/dataset/eu-referendum-results\n",
    "brexit_data_path = \"data/uk_brexit_referendum.csv\"\n",
    "ref = pandas.read_csv(brexit_data_path, index_col=\"Area_Code\")\n",
    "ref.info()\n",
    "\n",
    "# Source: https://geoportal.statistics.gov.uk/datasets/ed4fc01f849541bca7bb9044db5008a2_0/explore\n",
    "lads = geopandas.read_file(\n",
    "    \"data/Local_Authority_Districts.geojson\"\n",
    ").set_index(\"lad16cd\")\n",
    "lads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db20184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join geometries and votation results\n",
    "db = (\n",
    "    geopandas.GeoDataFrame(\n",
    "        lads.join(ref[[\"Pct_Leave\"]]), crs=lads.crs\n",
    "    )\n",
    "    .to_crs(epsg=3857)[\n",
    "        [\"OBJECTID\", \"lad16nm\", \"Pct_Leave\", \"geometry\"]\n",
    "    ]\n",
    "    .dropna()\n",
    ")\n",
    "db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb6466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "db.plot(\n",
    "    column=\"Pct_Leave\",\n",
    "    cmap=\"viridis\",\n",
    "    scheme=\"quantiles\",\n",
    "    k=6,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=0.0,\n",
    "    alpha=0.75,\n",
    "    legend=True,\n",
    "    legend_kwds={\"loc\": 2},\n",
    "    ax=ax,\n",
    ")\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    crs=db.crs,\n",
    "    source=contextily.providers.Esri.WorldTerrain,\n",
    ")\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ed0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate W from the GeoDataFrame\n",
    "w = weights.KNN.from_dataframe(db, k=8)\n",
    "# Row-standardization\n",
    "w.transform = \"R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eed6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a52902",
   "metadata": {},
   "outputs": [],
   "source": [
    "moran = esda.moran.Moran(db[\"Pct_Leave\"], w)\n",
    "geary = esda.geary.Geary(db[\"Pct_Leave\"], w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded4906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Moran's I:\", moran.I)\n",
    "print(\"Geary's C:\", geary.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e65874",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_moran(moran)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3feb69a",
   "metadata": {},
   "source": [
    "# Interpolation\n",
    "\n",
    "<a id='idw'></a>\n",
    "# IDW\n",
    "Exploit KNeighborsRegressor in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcbbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def knn_interpolation(gdf, value_column, n_neighbors=5, grid_resolution=100, weight_func='distance'):\n",
    "    # Ensure the geometry column contains Points\n",
    "    if not all(gdf.geometry.type == 'Point'):\n",
    "        raise ValueError(\"The GeoDataFrame should only contain Point geometries.\")\n",
    "\n",
    "    # \n",
    "    # Preprocessing\n",
    "    #\n",
    "    # Convert the GeoDataFrame to the appropriate projection for spatial analysis (meters)\n",
    "    gdf_projected = gdf.to_crs(epsg=3003)  # Use Italy 1 Mercator\n",
    "    # Extract coordinates (X, Y) and the values to interpolate\n",
    "    X = np.array([[point.x, point.y] for point in gdf_projected.geometry])\n",
    "    y = gdf_projected[value_column].values\n",
    "    \n",
    "    #\n",
    "    # Fit KNeighborsRegressor\n",
    "    #\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors, weights=weight_func)\n",
    "    knn.fit(X, y)\n",
    "    \n",
    "    #\n",
    "    # Plot\n",
    "    #\n",
    "    # Create a grid over the area of interest\n",
    "    xmin, ymin, xmax, ymax = gdf_projected.total_bounds\n",
    "    x_grid = np.linspace(xmin, xmax, grid_resolution)\n",
    "    y_grid = np.linspace(ymin, ymax, grid_resolution)\n",
    "    # Generate mesh grid of points for interpolation\n",
    "    xv, yv = np.meshgrid(x_grid, y_grid)\n",
    "    grid_points = np.column_stack([xv.ravel(), yv.ravel()])\n",
    "    # Predict values on the grid\n",
    "    z_pred = knn.predict(grid_points)    \n",
    "    # Reshape the predicted values to match the grid shape\n",
    "    z_pred = z_pred.reshape(grid_resolution, grid_resolution)    \n",
    "    # Create a GeoDataFrame from the grid points and predictions for plotting\n",
    "    interp_gdf = gpd.GeoDataFrame(\n",
    "        {'value': z_pred.ravel()},\n",
    "        geometry=[Point(x, y) for x, y in grid_points],\n",
    "        crs=gdf_projected.crs\n",
    "    )    \n",
    "    # Plot the original points and the interpolated map\n",
    "    fig, ax = plt.subplots(figsize=(18, 16))\n",
    "    # Plot the interpolated values as a heatmap (use a colormap like viridis or coolwarm)\n",
    "    plt.imshow(z_pred, extent=(xmin, xmax, ymin, ymax), origin='lower', cmap='coolwarm', alpha=0.6)\n",
    "    # Overlay the original points, colored by their actual values\n",
    "    sc = ax.scatter(\n",
    "        X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolor='k', s=50, label='Known Points', zorder=10\n",
    "    )\n",
    "    # Add title and labels\n",
    "    plt.title('KNeighborsRegressor Interpolation')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDW_weight(dist_list):\n",
    "# replace each distance with its weight\n",
    "    n=10\n",
    "    return [ 1/(d**n) for d in dist_list ]\n",
    "\n",
    "gdf = gpd.read_file(\"data/sf_bay_rainfall/sf_bay_rainfall.shp\")\n",
    "knn_interpolation(gdf, value_column='VALUE', n_neighbors=5, grid_resolution=200, weight_func=IDW_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27843974",
   "metadata": {},
   "source": [
    "<a id='kriging'></a>\n",
    "# Kriging\n",
    "Exploit the pykrige library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f7359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def kriging_interpolation(gdf, value_column, variogram_model='linear', grid_resolution=100):\n",
    "\n",
    "    # Ensure the geometry column contains Points\n",
    "    if not all(gdf.geometry.type == 'Point'):\n",
    "        raise ValueError(\"The GeoDataFrame should only contain Point geometries.\")\n",
    "\n",
    "    # Convert the GeoDataFrame to the appropriate projection for spatial analysis (meters)\n",
    "    gdf_projected = gdf.to_crs(epsg=3003)  # Use Italy 1 Mercator \n",
    "    # Extract coordinates (X, Y) and the values to interpolate\n",
    "    X = np.array([[point.x, point.y] for point in gdf_projected.geometry])\n",
    "    y = gdf_projected[value_column].values\n",
    "    # Define the area for interpolation by getting the bounding box of the input points\n",
    "    xmin, ymin, xmax, ymax = gdf_projected.total_bounds\n",
    "    # Create a grid over the area of interest\n",
    "    x_grid = np.linspace(xmin, xmax, grid_resolution)\n",
    "    y_grid = np.linspace(ymin, ymax, grid_resolution)\n",
    "    xv, yv = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "    \n",
    "    # Set up the Kriging model\n",
    "    kriging_model = OrdinaryKriging(\n",
    "        X[:, 0], X[:, 1], y, variogram_model=variogram_model, verbose=False, enable_plotting=False\n",
    "    )\n",
    "    # Perform the interpolation on the grid\n",
    "    z_pred, ss = kriging_model.execute(\"grid\", x_grid, y_grid)\n",
    "\n",
    "    \n",
    "    # Plot the original points and the interpolated map\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Plot the interpolated values as a heatmap (use a colormap like viridis or coolwarm)\n",
    "    img = ax.imshow(z_pred, extent=(xmin, xmax, ymin, ymax), origin='lower', cmap='coolwarm', alpha=0.6)\n",
    "\n",
    "    # Overlay the original points, colored by their actual values\n",
    "    sc = ax.scatter(\n",
    "        X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolor='k', s=50, label='Known Points', zorder=10\n",
    "    )\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title(f'Ordinary Kriging Interpolation ({variogram_model.capitalize()} Variogram)')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a65317",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"data/sf_bay_rainfall/sf_bay_rainfall.shp\")\n",
    "kriging_interpolation(gdf, value_column='VALUE', variogram_model='linear', grid_resolution=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad490b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSA_2023",
   "language": "python",
   "name": "gsa_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
