{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Author: Luca Pappalardo\n",
    "</br>Geospatial Analytics, Master degree in Data Science and Business Informatics, University of Pisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Analytics - Lesson 7: Flow generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train a Gravity model in San Francisco to predict flows in Denver\n",
    "\n",
    "1. Download checkin data and create a `TrajDataFrame`\n",
    "1. Create square tessellations for the two cities\n",
    "1. Compute the relevance of each tile\n",
    "1. Create `FlowDataFrame`s aggregating `TrajDataFrame`s \n",
    "5. Compute the total number of trips from each tile\n",
    "6. Fit a singly-constrained Gravity using trips in San Francisco\n",
    "7. Use the fitted model to predict flows in Denver\n",
    "\n",
    "\n",
    "8. **Qualitative evaluation**: visualise the performance of the model against a baseline random model\n",
    "9. **Quantitative evaluation**: compute performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gravity model of human mobility\n",
    "\n",
    "$T_{ij} \\propto \\frac{pop_i^{\\alpha_1} \\cdot pop_j^{\\alpha_2}}{r_{ij}^\\beta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import skmob\n",
    "from skmob.utils import utils, constants\n",
    "from skmob.tessellation import tilers\n",
    "from skmob.utils.plot import plot_gdf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create a `TrajDataFrame` from <a href=\"https://snap.stanford.edu/data/loc-brightkite.html\">Brightkite</a> checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first download checkins using pandas\n",
    "url = \"https://snap.stanford.edu/data/loc-brightkite_totalCheckins.txt.gz\"\n",
    "#url = 'data/loc-brightkite_totalCheckins.txt.gz'\n",
    "df = pd.read_csv(url, sep='\\t', header=0, nrows=100000, \n",
    "                 names=['user', 'check-in_time', 'latitude', 'longitude', 'location id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# convert the DataFrame into a TrajDataFrame\n",
    "tdf = skmob.TrajDataFrame(df, latitude='latitude', longitude='longitude', datetime='check-in_time', user_id='user')\n",
    "tdf.crs = 'epsg:4326'\n",
    "print('number of rows: %s' %len(tdf))\n",
    "print(type(tdf))\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.plot_trajectory(max_users=10, max_points=1000, zoom=4, start_end_markers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(tiles='openstreetmap', zoom_start=12, control_scale=True)\n",
    "HeatMap(tdf[:50000][['lat', 'lng']].values).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create square tessellations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training city: San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmob.utils.plot import plot_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it retrieve information from the web\n",
    "tess_train = tilers.tiler.get(\"squared\",  \n",
    "                              base_shape=\"San Francisco, California\", \n",
    "                              meters=2500)\n",
    "len(tess_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gdf(tess_train, zoom=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Test city: Denver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_test = tilers.tiler.get(\"squared\", meters=2500, \n",
    "                             base_shape=\"Denver, Colorado\")\n",
    "len(tess_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gdf(tess_test, zoom=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compute the relevance of each tile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. assign each point to the corresponding tile in San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_tid = tdf.mapping(tess_train, remove_na=True)\n",
    "tdf_tid.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2. compute the relevance of each tile in San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevances = tdf_tid.groupby(by='tile_ID').count()[['lat']].rename(\n",
    "    columns={'lat': 'relevance'})\n",
    "relevances /= relevances.sum() # normalize\n",
    "\n",
    "tess_train = tess_train.merge(relevances, right_index=True, left_on='tile_ID', how='left').fillna(0.)\n",
    "tess_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Do the same for Denver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_tid = tdf.mapping(tess_test, remove_na=True)\n",
    "relevances = tdf_tid.groupby(by='tile_ID').count()[['lat']].rename(columns={'lat': 'relevance'})\n",
    "# normalise\n",
    "relevances /= relevances.sum()\n",
    "\n",
    "tess_test = tess_test.merge(relevances, right_index=True, left_on='tile_ID', how='left').fillna(0.)\n",
    "tess_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_colormap(tessellation, minval=1e-6):\n",
    "    # define the colormap\n",
    "    normc = mpl.colors.LogNorm(vmin=max(tessellation['relevance'].min(), minval), \\\n",
    "                               vmax=tessellation['relevance'].max())\n",
    "    s_m = mpl.cm.ScalarMappable(cmap='jet', norm=normc)\n",
    "    return s_m\n",
    "\n",
    "def get_color(x):\n",
    "    return mpl.colors.to_hex(s_m.to_rgba(x['relevance'] + 1e-12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "s_m = define_colormap(tess_train)\n",
    "plot_gdf(tess_train, zoom=10, popup_features=['relevance'], \\\n",
    "         style_func_args={'color': get_color, 'fillColor' : get_color})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# the same for Denver\n",
    "s_m = define_colormap(tess_test)\n",
    "plot_gdf(tess_test, zoom=10, popup_features=['relevance'], \\\n",
    "         style_func_args={'color': get_color, 'fillColor' : get_color})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create `FlowDataFrame`s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for San Francisco\n",
    "fdf_train = tdf.to_flowdataframe(tess_train, self_loops=False)\n",
    "print(fdf_train['flow'].sum(), fdf_train['flow'].max())\n",
    "fdf_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# for Denver\n",
    "fdf_test = tdf.to_flowdataframe(tess_test, self_loops=False)\n",
    "print(fdf_test['flow'].sum(), fdf_test['flow'].max())\n",
    "fdf_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# plot flows in San Francisco\n",
    "fdf_train.plot_flows(min_flow=5, zoom=10, tiles='cartodbpositron', flow_weight=2, opacity=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# plot flows in Denver\n",
    "fdf_test.plot_flows(min_flow=5, zoom=10, tiles='cartodbpositron', flow_weight=2, opacity=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compute number of trips from each tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total outflows excluding self loops in San Francisco\n",
    "tot_outflows = fdf_train[fdf_train['origin'] != fdf_train['destination']] \\\n",
    "    .groupby(by='origin', axis=0)[['flow']].sum().fillna(0).rename(columns={'flow': 'tot_outflow'})\n",
    "\n",
    "if 'tot_outflow' not in tess_train.columns:\n",
    "    tess_train = tess_train.merge(tot_outflows, right_index=True, left_on='tile_ID', how='left').fillna(0.).sort_values(by='tot_outflow', ascending=False)\n",
    "tess_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# total outflows excluding self loops in Denver\n",
    "tot_outflows = fdf_test[fdf_test['origin'] != fdf_test['destination']] \\\n",
    "    .groupby(by='origin', axis=0)[['flow']].sum().fillna(0).rename(columns={'flow': 'tot_outflow'})\n",
    "\n",
    "if 'tot_outflow' not in tess_test.columns:\n",
    "    tess_test = tess_test.merge(tot_outflows, right_index=True, left_on='tile_ID', how='left').fillna(0.).sort_values(by='tot_outflow', ascending=False)\n",
    "tess_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fit a singly-constrained Gravity Model using trips in San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Gravity class\n",
    "from skmob.models.gravity import Gravity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Gravity` class has two public methods:\n",
    "- `fit` fits the method parameters from data;\n",
    "- `generate` generates the flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Fit the gravity model's parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravity_singly_fitted = Gravity(gravity_type='singly constrained')\n",
    "print(gravity_singly_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravity_singly_fitted.fit(fdf_train, relevance_column='relevance')\n",
    "print(gravity_singly_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Use the fitted model to predict the flows in Denver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "sc_fdf_fitted = gravity_singly_fitted.generate(tess_test, \n",
    "                tile_id_column='tile_ID', \n",
    "                tot_outflows_column='tot_outflow', \n",
    "                relevance_column= 'relevance', out_format='flows')\n",
    "sc_fdf_fitted.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sc_fdf_fitted.plot_flows(min_flow=5, zoom=10, tiles='cartodbpositron', flow_weight=2, opacity=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "denv_map = sc_fdf_fitted.plot_flows(min_flow=5, zoom=10, tiles='cartodbpositron', flow_weight=2, opacity=0.25)\n",
    "fdf_test.plot_flows(map_f=denv_map, min_flow=5, zoom=10, tiles='cartodbpositron', flow_weight=2, opacity=0.25, flow_color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Qualitative evaluation\n",
    "visualise the model's performance against a baseline\n",
    "#### 1. Create a baseline model (without dependence on relevance and distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Gravity(gravity_type='singly constrained', \n",
    "                   deterrence_func_args=[0.], destination_exp=0.)\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "baseline_fdf = baseline.generate(tess_test, \n",
    "                                   tile_id_column='tile_ID', \n",
    "                                   tot_outflows_column='tot_outflow', \n",
    "                                   relevance_column= 'relevance',\n",
    "                                   out_format='flows')\n",
    "baseline_fdf[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "baseline_fdf.plot_flows(min_flow=5, zoom=10, \n",
    "                        tiles='cartodbpositron', flow_weight=2, opacity=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "denv_base_map = baseline_fdf.plot_flows(min_flow=5, zoom=10, tiles='cartodbpositron', flow_weight=2, opacity=0.25)\n",
    "fdf_test.plot_flows(map_f=denv_base_map, min_flow=5, zoom=10, tiles='cartodbpositron', flow_weight=2, opacity=0.25, flow_color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Compare real flows against generated flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = fdf_test.merge(sc_fdf_fitted, on=['origin', 'destination'])[['flow_x', 'flow_y']].values\n",
    "xy_baseline = fdf_test.merge(baseline_fdf, on=['origin', 'destination'])[['flow_x', 'flow_y']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(xy[:,0], xy[:,1], '.', label='Gravity')\n",
    "plt.plot(xy_baseline[:,0], xy_baseline[:,1], '*', alpha=0.5, label='Baseline')\n",
    "x = np.logspace(0, np.log10(np.max(xy)))\n",
    "plt.plot(x, x, '--k')\n",
    "plt.xlabel('Real flow'); plt.ylabel('Model flow')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.loglog(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quantitative evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmob.measures.evaluation import r_squared, mse, spearman_correlation, pearson_correlation, common_part_of_commuters, common_part_of_commuters_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [r_squared, mse, spearman_correlation, pearson_correlation, common_part_of_commuters, common_part_of_commuters_distance]\n",
    "names = ['r_squared', 'mse', 'spearman_correlation', 'pearson_correlation', 'common_part_of_commuters', 'common_part_of_commuters_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('Metric:  Gravity - Baseline')\n",
    "print('---------------------------')\n",
    "for i, metric in enumerate(metrics):\n",
    "    m = metric(xy[:, 0], xy[:, 1])\n",
    "    b = metric(xy_baseline[:, 0], xy_baseline[:, 1])\n",
    "    print(\"%s:   %s - %s\" % (names[i], np.round(m, 3), np.round(b, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download from figshare this [flows dataset](https://figshare.com/collections/Inter-urban_interactions_of_mobility_via_cellular_position_tracking_in_the_southeast_Songliao_Basin_Northeast_China/4226183), create a tessellation and a `FlowDataFrame`; plot them together using skmob. Then: \n",
    "- split the `FlowDataFrame` into a training set and a test set; \n",
    "- train a `Gravity` model on the training set\n",
    "- test the model's goodness on the test set (qualitative and quantitative evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, json, io\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import skmob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_links = {\n",
    "'positions' : 'https://figshare.com/ndownloader/files/14005292',\n",
    "'flows' : 'https://figshare.com/ndownloader/files/14884442',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(dataset_links['positions'], stream=True)\n",
    "print(r.text.replace('\\r', '\\n'), file=open('positions.csv','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_df = pd.read_csv('positions.csv')\n",
    "gdf = gpd.GeoDataFrame(positions_df, \n",
    "                       geometry=gpd.points_from_xy(positions_df['Longitude'], positions_df['Latitude'])).drop(['Longitude', 'Latitude'], axis=1).rename(columns={'Location': 'tile_ID'})\n",
    "gdf['tile_ID'] = gdf['tile_ID'].astype('str')\n",
    "gdf.crs = 'epsg:4326'\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(dataset_links['flows'], stream=True)\n",
    "print(r.text, file=open('flows.csv','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_df = pd.read_csv('flows.csv')\n",
    "flows_df['Origin'].astype('str')\n",
    "flows_df['Destination'].astype('str')\n",
    "flows_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total outflows excluding self loops in San Francisco\n",
    "tot_outflows_df = flows_df[flows_df['Origin'] != flows_df['Destination']] \\\n",
    "    .groupby(by='Origin', axis=0)[['Weight']].sum().fillna(0).rename(columns={'Weight': 'tot_outflow'})\n",
    "tot_outflows_df.index = tot_outflows_df.index.astype('str')\n",
    "gdf = gdf.merge(tot_outflows_df, right_index=True, left_on='tile_ID', how='left').fillna(0.).sort_values(by='tot_outflow', ascending=False)\n",
    "gdf['relevance'] = gdf['tot_outflow'] / gdf['tot_outflow'].sum()    \n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = skmob.FlowDataFrame(flows_df, \n",
    "                          origin='Origin', destination='Destination', flow='Weight', \n",
    "                          tile_id='tile_ID', tessellation=gdf)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmob.models import gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravity_singly = gravity.Gravity(gravity_type='singly constrained')\n",
    "print(gravity_singly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "gen_fdf = gravity_singly.generate(gdf, \n",
    "                tile_id_column='tile_ID', \n",
    "                tot_outflows_column='tot_outflow', \n",
    "                relevance_column= 'relevance', out_format='flows')\n",
    "gen_fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fdf.plot_flows(min_flow=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = gravity.Gravity(gravity_type='singly constrained', \n",
    "                   deterrence_func_args=[0.], destination_exp=0.)\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "baseline_fdf = baseline.generate(gdf, \n",
    "                                   tile_id_column='tile_ID', \n",
    "                                   tot_outflows_column='tot_outflow', \n",
    "                                   relevance_column= 'relevance',\n",
    "                                   out_format='flows')\n",
    "baseline_fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baseline_fdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = fdf.merge(gen_fdf, on=['origin', 'destination'])[['flow_x', 'flow_y']].values\n",
    "xy_baseline = fdf.merge(baseline_fdf, on=['origin', 'destination'])[['flow_x', 'flow_y']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xy[:,0], xy[:,1], '.', label='Gravity')\n",
    "plt.plot(xy_baseline[:,0], xy_baseline[:,1], '*', alpha=0.5, label='Baseline')\n",
    "x = np.logspace(0, np.log10(np.max(xy)))\n",
    "plt.plot(x, x, '--k')\n",
    "plt.xlabel('Real flow'); plt.ylabel('Model flow')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.loglog(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmob.measures.evaluation import r_squared, mse, spearman_correlation, pearson_correlation, common_part_of_commuters, common_part_of_commuters_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [r_squared, mse, spearman_correlation, pearson_correlation, common_part_of_commuters, common_part_of_commuters_distance]\n",
    "names = ['r_squared', 'mse', 'spearman_correlation', 'pearson_correlation', 'common_part_of_commuters', 'common_part_of_commuters_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Metric:  Gravity - Baseline')\n",
    "print('---------------------------')\n",
    "for i, metric in enumerate(metrics):\n",
    "    m = metric(xy[:, 0], xy[:, 1])\n",
    "    b = metric(xy_baseline[:, 0], xy_baseline[:, 1])\n",
    "    print(\"%s:   %s - %s\" % (names[i], np.round(m, 3), np.round(b, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:GSA]",
   "language": "python",
   "name": "gsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
